{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babc9158",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac25e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.2 kB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,143 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \n",
      "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,827 kB]\n",
      "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,530 kB]\n",
      "Get:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \n",
      "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \n",
      "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]\n",
      "Get:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [44.9 kB]\n",
      "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,452 kB] \n",
      "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,982 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [60.9 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,181 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,861 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
      "Fetched 37.7 MB in 5s (8,003 kB/s)                           \n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 177 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update && sudo apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5291a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torch-2.9.1%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchvision-0.24.1%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.9.1%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting torchlibrosa\n",
      "  Downloading torchlibrosa-0.1.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting museval\n",
      "  Downloading museval-0.4.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torchcontrib\n",
      "  Downloading torchcontrib-0.0.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: datasets[audio] in /usr/local/lib/python3.11/dist-packages (4.1.1)\n",
      "Collecting datasets[audio]\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (1.26.4)\n",
      "Collecting pyarrow>=21.0.0 (from datasets[audio])\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets[audio]) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (1.0.0rc2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]) (6.0.3)\n",
      "Collecting torchcodec>=0.6.0 (from datasets[audio])\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchcodec-0.8.1%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (0.15.2)\n",
      "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (1.8.2)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.5)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
      "Collecting musdb>=0.4.0 (from museval)\n",
      "  Downloading musdb-0.4.3-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: simplejson>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from museval) (3.20.1)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from museval) (4.25.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets[audio]) (3.12.15)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets[audio]) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets[audio]) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets[audio]) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets[audio]) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets[audio]) (0.16.0)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets[audio]) (0.19.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets[audio]) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
      "Collecting stempeg>=0.2.4 (from musdb>=0.4.0->museval)\n",
      "  Downloading stempeg-0.2.6-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (from musdb>=0.4.0->museval) (25.7.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets[audio]) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets[audio]) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets[audio]) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets[audio]) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets[audio]) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets[audio]) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets[audio]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets[audio]) (2025.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets[audio]) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets[audio]) (2.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->museval) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->museval) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->museval) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->museval) (0.26.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[audio]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[audio]) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[audio]) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[audio]) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[audio]) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[audio]) (1.20.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.17.0)\n",
      "Collecting ffmpeg-python>=0.2.0 (from stempeg>=0.2.4->musdb>=0.4.0->museval)\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets[audio]) (1.3.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets[audio]) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets[audio]) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets[audio]) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets[audio]) (2024.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets[audio]) (8.3.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.4->musdb>=0.4.0->museval) (1.0.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets[audio]) (2024.2.0)\n",
      "Downloading lightning-2.5.6-py3-none-any.whl (827 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torch-2.9.1%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl (833.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.0/833.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m978.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchvision-0.24.1%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchaudio-2.9.1%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchlibrosa-0.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading museval-0.4.1-py2.py3-none-any.whl (20 kB)\n",
      "Downloading musdb-0.4.3-py2.py3-none-any.whl (13 kB)\n",
      "Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchcodec-0.8.1%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stempeg-0.2.6-py3-none-any.whl (963 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.2/963.2 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: torchcontrib\n",
      "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-py3-none-any.whl size=7516 sha256=57af74cbd07ebb1e8c4b5908a94722e7f97985f49378c57b7485e7e89c42306b\n",
      "  Stored in directory: /root/.cache/pip/wheels/f1/87/f6/b3c995670297d282da49c39ea210c39fc8089c27f453bc1c42\n",
      "Successfully built torchcontrib\n",
      "Installing collected packages: torchcontrib, nvidia-cusparselt-cu12, triton, torchcodec, sympy, pyarrow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ffmpeg-python, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio, stempeg, musdb, datasets, torchvision, torchlibrosa, museval, lightning\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu124\n",
      "    Uninstalling torch-2.6.0+cu124:\n",
      "      Successfully uninstalled torch-2.6.0+cu124\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.6.0+cu124\n",
      "    Uninstalling torchaudio-2.6.0+cu124:\n",
      "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.1.1\n",
      "    Uninstalling datasets-4.1.1:\n",
      "      Successfully uninstalled datasets-4.1.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cu124\n",
      "    Uninstalling torchvision-0.21.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.1+cu126 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.4.1 ffmpeg-python-0.2.0 lightning-2.5.6 musdb-0.4.3 museval-0.4.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.6.77 pyarrow-22.0.0 stempeg-0.2.6 sympy-1.14.0 torch-2.9.1+cu126 torchaudio-2.9.1+cu126 torchcodec-0.8.1+cu126 torchcontrib-0.0.2 torchlibrosa-0.1.0 torchvision-0.24.1+cu126 triton-3.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U datasets[audio] librosa lightning torch torchvision torchaudio torchlibrosa museval torchcontrib --extra-index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b4326",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6a3462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222defce169c4cd891e963c120c9f6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/479 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb97fe8c4794cd5baff9df5e4bc20da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00008.parquet:   0%|          | 0.00/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4bbf257a1d4cf1944de296b4ad77f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00008.parquet:   0%|          | 0.00/284M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de623f4ed55430e8327b108813cb03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00002-of-00008.parquet:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80a726b872e4e6fb784efdcf947a173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00003-of-00008.parquet:   0%|          | 0.00/152M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d735d802f8c42108e69acca63e48692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00004-of-00008.parquet:   0%|          | 0.00/117M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc93f662c6d24c9aab92c0272d8ef12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00005-of-00008.parquet:   0%|          | 0.00/30.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02065cc232e24a85a2180095303dc2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00006-of-00008.parquet:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ce86a449e4488c9a7461e15928e9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00007-of-00008.parquet:   0%|          | 0.00/429M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b1ebcea5b846e481d403b359ec9c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from datasets import load_dataset\n",
    "\n",
    "repo_id = \"kuross/dl-proj-classification\"\n",
    "dataset = load_dataset(repo_id)\n",
    "train_dataset = dataset['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbe601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Split Verification (Approximate 80/10/10 Split) ---\n",
      "Total size: 5276 samples\n",
      "-------------------------\n",
      "Train size: 4220 (79.98%)\n",
      "Validation size: 528 (10.01%)\n",
      "Test size: 528 (10.01%)\n",
      "-------------------------\n",
      "New Dataset Structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file', 'label', 'duration'],\n",
      "        num_rows: 4220\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['file', 'label', 'duration'],\n",
      "        num_rows: 528\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['file', 'label', 'duration'],\n",
      "        num_rows: 528\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "repo_id = \"kuross/dl-proj-classification\"\n",
    "dataset = load_dataset(repo_id)\n",
    "\n",
    "# Start with the original 'train' split\n",
    "original_train_dataset = dataset['train']\n",
    "\n",
    "# --- Step 1: Split into Temporary Train/Validation and Test ---\n",
    "\n",
    "# Allocate a portion (e.g., 10%) for the final TEST set\n",
    "temp_splits = original_train_dataset.train_test_split(\n",
    "    test_size=0.10, # 10% for the final test set\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_dataset = temp_splits['test']          # 10% of the original data\n",
    "temp_train_val = temp_splits['train']       # 90% of the original data\n",
    "\n",
    "# --- Step 2: Split the remaining data into Train and Validation ---\n",
    "\n",
    "# Split the 90% remaining data (temp_train_val) into 80% Train and 10% Validation\n",
    "# We calculate the ratio relative to the remaining data (90%)\n",
    "# If we want 10% of the total (10 / 90) = 1/9 ≈ 0.1111\n",
    "val_ratio_of_temp = 0.1111 \n",
    "\n",
    "final_splits = temp_train_val.train_test_split(\n",
    "    test_size=val_ratio_of_temp, # This is approximately 1/9th of the remaining data\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "train_dataset = final_splits['train']       # ~80% of the total data\n",
    "val_dataset = final_splits['test']          # ~10% of the total data\n",
    "\n",
    "# --- Final Dataset Structure ---\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"--- Split Verification (Approximate 80/10/10 Split) ---\")\n",
    "total_size = len(original_train_dataset)\n",
    "print(f\"Total size: {total_size} samples\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"Train size: {len(dataset['train'])} ({len(dataset['train'])/total_size:.2%})\")\n",
    "print(f\"Validation size: {len(dataset['val'])} ({len(dataset['val'])/total_size:.2%})\")\n",
    "print(f\"Test size: {len(dataset['test'])} ({len(dataset['test'])/total_size:.2%})\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"New Dataset Structure: {dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc34427",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63c2fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Base from HTS AT Repository\n",
    "from external.hts_audio_transformer import config\n",
    "\n",
    "## Add / Modify Configurations\n",
    "config.debug = True\n",
    "config.waveform_length = 128000\n",
    "config.max_epoch = 5\n",
    "config.classes_num = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144c92c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f5a37",
   "metadata": {},
   "source": [
    "### Resampling to 32000 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f69817d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': <datasets.features._torchcodec.AudioDecoder at 0x7abf2ebfdc90>,\n",
       " 'label': 0,\n",
       " 'duration': 0.0}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9265680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's audio has been resampled to 32000 Hz\n",
      "Dataset's audio has been resampled to 32000 Hz\n",
      "Dataset's audio has been resampled to 32000 Hz\n"
     ]
    }
   ],
   "source": [
    "from datasets import Audio, Dataset\n",
    "\n",
    "\n",
    "def resample_audio(dataset: Dataset, sampling_rate: int = 32000, audio_column_name: str = 'file'):\n",
    "    resampled_dataset = dataset.cast_column(\n",
    "        audio_column_name,\n",
    "        Audio(sampling_rate=sampling_rate)\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset's audio has been resampled to {sampling_rate} Hz\")\n",
    "\n",
    "    return resampled_dataset\n",
    "\n",
    "resampled_train_dataset = resample_audio(train_dataset)\n",
    "resampled_val_dataset = resample_audio(val_dataset)\n",
    "resampled_test_dataset = resample_audio(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d78145",
   "metadata": {},
   "source": [
    "### Formatting for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5f520be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def format_dataset(dataset: Dataset, audio_column_name: str = 'file'):\n",
    "\n",
    "    def format_function(record, idx):\n",
    "        audio = record[audio_column_name]\n",
    "\n",
    "        return {\n",
    "            \"audio_name\": str(idx),\n",
    "            \"target\": record['label'],\n",
    "            \"waveform\": audio['array'],\n",
    "            \"real_len\": len(audio['array'])\n",
    "        }\n",
    "\n",
    "    formatted_dataset = dataset.map(\n",
    "        format_function,\n",
    "        with_indices=True,\n",
    "        remove_columns=[audio_column_name, 'label', 'duration']\n",
    "    ).with_format(\"torch\")\n",
    "\n",
    "    return formatted_dataset\n",
    "\n",
    "\n",
    "formatted_train_dataset = format_dataset(resampled_train_dataset)\n",
    "formatted_val_dataset = format_dataset(resampled_val_dataset)\n",
    "formatted_test_dataset = format_dataset(resampled_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "469cb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For saving the formatting\n",
    "# SAVE_PATH = \"./formatted_audio_data\"\n",
    "# formatted_train_dataset.save_to_disk(SAVE_PATH)\n",
    "\n",
    "# print(f\"Dataset successfully saved to: {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "061040fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading\n",
    "# from datasets import load_from_disk\n",
    "# import torch\n",
    "\n",
    "# SAVE_PATH = \"./formatted_audio_data\"\n",
    "\n",
    "# # 1. Load the dataset from the disk directory\n",
    "# loaded_dataset = load_from_disk(SAVE_PATH)\n",
    "\n",
    "# # 2. Re-apply the PyTorch format for training compatibility\n",
    "# # This ensures it yields torch.Tensors when iterated over.\n",
    "# loaded_dataset_torch = loaded_dataset.with_format(\"torch\")\n",
    "\n",
    "# print(f\"Dataset successfully loaded from: {SAVE_PATH}\")\n",
    "# print(f\"Loaded dataset object type: {type(loaded_dataset_torch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a5e17c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# NUM_CLASSES = 527\n",
    "\n",
    "# def format_audio_data_with_index(example, idx):\n",
    "#     \"\"\"\n",
    "#     Formats the audio data, using the dataset index as the 'name'.\n",
    "    \n",
    "#     Args:\n",
    "#         example (dict): The dictionary containing the row data.\n",
    "#         idx (int): The index of the row in the dataset.\n",
    "#     \"\"\"\n",
    "#     # Assuming the audio has been correctly decoded by the map function\n",
    "#     audio_info = example[AUDIO_COLUMN_NAME]\n",
    "\n",
    "#     # Get the single integer label\n",
    "#     label_int = example['label']\n",
    "    \n",
    "#     # 1. Create a NumPy array of zeros with shape (NUM_CLASSES,)\n",
    "#     one_hot_vector = np.zeros(NUM_CLASSES, dtype=np.float32)\n",
    "    \n",
    "#     # 2. Set the index corresponding to the label to 1.0\n",
    "#     one_hot_vector[label_int] = 1.0\n",
    "\n",
    "#     return {\n",
    "#         \"audio_name\": str(idx),\n",
    "#         \"target\": one_hot_vector,\n",
    "#         \"waveform\": audio_info['array'],\n",
    "#         \"real_len\": len(audio_info['array'])\n",
    "#     }\n",
    "\n",
    "# resampled_train_dataset = resampled_train_dataset.select(range(1000))\n",
    "\n",
    "# formatted_train_dataset = resampled_train_dataset.map(\n",
    "#     format_audio_data_with_index,\n",
    "#     with_indices=True,\n",
    "#     remove_columns=[AUDIO_COLUMN_NAME, 'label', 'duration']\n",
    "# ).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9881e",
   "metadata": {},
   "source": [
    "### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b3f2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def ensure_fixed_waveform_length(waveform: torch.Tensor, target_length: int = 128000) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Ensures an audio waveform tensor is exactly the target_length by cropping the start \n",
    "    or zero-padding the end, using optimized PyTorch operations.\n",
    "\n",
    "    Args:\n",
    "        waveform (torch.Tensor): The input audio time series tensor (e.g., shape [L]).\n",
    "        target_length (int): The required length for the output waveform.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The processed waveform with the exact target_length.\n",
    "    \"\"\"\n",
    "    original_length = waveform.size(0)\n",
    "\n",
    "    if original_length > target_length:\n",
    "        return waveform[:target_length]\n",
    "        \n",
    "    elif original_length < target_length:\n",
    "        padding_amount = target_length - original_length\n",
    "        padding_tuple = (0, padding_amount)\n",
    "\n",
    "        return F.pad(waveform, padding_tuple, mode='constant', value=0.0)\n",
    "        \n",
    "    else:\n",
    "        return waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c57a05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "import random\n",
    "\n",
    "class HTSATDataset(Dataset):\n",
    "    def __init__(self, dataset, config, eval_mode = False):\n",
    "        self.dataset = dataset\n",
    "        self.config = config       \n",
    "        self.total_size = len(self.dataset)\n",
    "        self.queue = [*range(self.total_size)]\n",
    "        logging.info(\"total dataset size: %d\" %(self.total_size))\n",
    "        if not eval_mode:\n",
    "            self.generate_queue()\n",
    "\n",
    "    def generate_queue(self):\n",
    "        random.shuffle(self.queue)\n",
    "        logging.info(\"queue regenerated:%s\" %(self.queue[-5:]))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get actual index of the record\n",
    "        p = self.queue[index]\n",
    "\n",
    "        # Process waveform into fixed length\n",
    "        waveform_processed = ensure_fixed_waveform_length(self.dataset[p][\"waveform\"], config.waveform_length)\n",
    "\n",
    "        # one-hot target if required\n",
    "        if config.loss_type == 'clip_bce':\n",
    "            label_tensor = torch.as_tensor(self.dataset[p][\"target\"], dtype=torch.long)\n",
    "            target = F.one_hot(label_tensor, num_classes=config.classes_num).float()\n",
    "        else:\n",
    "            target = torch.as_tensor(self.dataset[p][\"target\"])\n",
    "\n",
    "        data_dict = {\n",
    "            \"audio_name\": self.dataset[p][\"audio_name\"],\n",
    "            \"waveform\": waveform_processed,\n",
    "            \"real_len\": len(waveform_processed),\n",
    "            \"target\": target\n",
    "        }\n",
    "        logging.info(f\"getitem: {p}\")\n",
    "        return data_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "\n",
    "\n",
    "htsat_train_dataset = HTSATDataset(formatted_train_dataset, config)\n",
    "htsat_val_dataset = HTSATDataset(formatted_val_dataset, config, True)\n",
    "htsat_test_dataset = HTSATDataset(formatted_test_dataset, config, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch.optim as optim\n",
    "import bisect\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score\n",
    "\n",
    "from external.hts_audio_transformer.utils import get_loss_func\n",
    "\n",
    "\n",
    "class HTSATModel(L.LightningModule):\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        # self.dataset = dataset\n",
    "        self.loss_func = get_loss_func(config.loss_type)\n",
    "        self.test_step_outputs = []\n",
    "    \n",
    "    def forward(self, x, mix_lambda = None):\n",
    "        output_dict = self.model(x)\n",
    "        return output_dict[\"clipwise_output\"] , output_dict[\"framewise_output\"]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.device_type = next(self.parameters()).device\n",
    "        mix_lambda = None\n",
    "        \n",
    "        pred, _ = self(batch[\"waveform\"], mix_lambda)\n",
    "        loss = self.loss_func(pred, batch[\"target\"])\n",
    "        self.log(\"loss\", loss, on_epoch= True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, self.parameters()),\n",
    "            lr = self.config.learning_rate, \n",
    "            betas = (0.9, 0.999), eps = 1e-08, weight_decay = 0.05, \n",
    "        )\n",
    "        # Change: SWA, deprecated\n",
    "        # optimizer = SWA(optimizer, swa_start=10, swa_freq=5)\n",
    "        def lr_foo(epoch):       \n",
    "            if epoch < 3:\n",
    "                # warm up lr\n",
    "                lr_scale = self.config.lr_rate[epoch]\n",
    "            else:\n",
    "                # warmup schedule\n",
    "                lr_pos = int(-1 - bisect.bisect_left(self.config.lr_scheduler_epoch, epoch))\n",
    "                if lr_pos < -3:\n",
    "                    lr_scale = max(self.config.lr_rate[0] * (0.98 ** epoch), 0.03 )\n",
    "                else:\n",
    "                    lr_scale = self.config.lr_rate[lr_pos]\n",
    "            return lr_scale\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lr_foo\n",
    "        )\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pred, _ = self(batch[\"waveform\"])\n",
    "        return [pred.detach(), batch[\"target\"].detach()]\n",
    "    \n",
    "    def time_shifting(self, x, shift_len):\n",
    "        shift_len = int(shift_len)\n",
    "        new_sample = torch.cat([x[:, shift_len:], x[:, :shift_len]], axis = 1)\n",
    "        return new_sample \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        pred, pred_map = self(batch[\"waveform\"])    # pred: (B, C) | pred_map: (B, window_size, C)\n",
    "        target = batch['target']                    # target: (B, C)\n",
    "        loss = self.loss_func(pred, target)\n",
    "\n",
    "        output = {\n",
    "            'pred': pred.detach().cpu(), \n",
    "            'target': target.detach().cpu(),\n",
    "        }\n",
    "        self.test_step_outputs.append(output)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def evaluate_metric(self, pred, target):\n",
    "        # Convert to Numpy for use\n",
    "        pred_numpy = pred.numpy()\n",
    "        target_numpy = target.numpy()\n",
    "\n",
    "        # Accuracy\n",
    "        predicted_labels = np.argmax(pred_numpy, axis=1)\n",
    "        true_labels = np.argmax(target_numpy, axis=1)\n",
    "        acc = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "        # Loss\n",
    "        loss = self.loss_func(pred, target).item()\n",
    "\n",
    "        # mAP\n",
    "        mAP = average_precision_score(target_numpy, pred_numpy, average='macro')\n",
    "\n",
    "        return {\n",
    "            \"acc\": acc,\n",
    "            \"loss\": loss,\n",
    "            \"mAP\": mAP\n",
    "        }\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_step_outputs = self.test_step_outputs\n",
    "\n",
    "        all_preds = torch.cat([x['pred'] for x in test_step_outputs], dim=0)\n",
    "        all_targets = torch.cat([x['target'] for x in test_step_outputs], dim=0)\n",
    "    \n",
    "        metric_results = self.evaluate_metric(all_preds, all_targets)\n",
    "\n",
    "        self.log_dict(metric_results,  on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dea6962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "minimal_trainer = L.Trainer(\n",
    "    # --- Essentials ---\n",
    "    max_epochs=config.max_epoch,         # Stop condition for training\n",
    "    default_root_dir=\"./checkpoints\",     # Where logs and checkpoints go\n",
    "\n",
    "    # --- Minimal Device Configuration (Assuming single GPU/CPU) ---\n",
    "    # Setting devices=1 for modern Lightning (replaces gpus=1)\n",
    "    # If device_num is 0 or 1, you can often just omit this\n",
    "    # to let Lightning detect the device, but specifying is safer.\n",
    "    # Note: If you need to specify CPU/GPU, use: devices=1, accelerator='gpu'/'cpu'\n",
    "    \n",
    "    # Keeping 'gpus' for compatibility with older PL versions in your original code:\n",
    "    # gpus=device_num, \n",
    "    # log_every_n_steps = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a84b637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from external.hts_audio_transformer.model.htsat import HTSAT_Swin_Transformer\n",
    "\n",
    "sed_model = HTSAT_Swin_Transformer(\n",
    "    num_classes=config.classes_num,\n",
    "    config = config\n",
    ")\n",
    "model = HTSATModel(sed_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f6ac7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = htsat_train_dataset,\n",
    "    num_workers = config.num_workers,\n",
    "    # num_workers = 0,\n",
    "    batch_size = 10,\n",
    "    shuffle = False,\n",
    "    # sampler = train_sampler\n",
    ")\n",
    "\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = htsat_val_dataset,\n",
    "    num_workers = config.num_workers,\n",
    "    # num_workers = 0,\n",
    "    batch_size = 10,\n",
    "    shuffle = False,\n",
    "    # sampler = train_sampler\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = htsat_test_dataset,\n",
    "    num_workers = config.num_workers,\n",
    "    # num_workers = 0,\n",
    "    batch_size = 10,\n",
    "    shuffle = False,\n",
    "    # sampler = train_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ad410750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name  | Type                   | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model | HTSAT_Swin_Transformer | 28.6 M | train\n",
      "---------------------------------------------------------\n",
      "27.6 M    Trainable params\n",
      "1.1 M     Non-trainable params\n",
      "28.6 M    Total params\n",
      "114.564   Total estimated model params size (MB)\n",
      "217       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed84663c0d1b46748edf6d4e87dbb693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77769ddf8fb4b0082dad3a1f97c6583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626acdb891464814a7c0cbd61c0c563d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d400b712aee44069aa680b6fe7f18da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3185d1054a8b47f1b01a2b7f2f88cf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2768bc87054f1d8020637cddcb0046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ef0913fe164162b8e94a121041eff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "minimal_trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5eba254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model.model\n",
    "model = HTSATModel(trained_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "90a650d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be68e240b6d94a0ea547ce68e6fa2839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            acc            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.939393937587738     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           loss            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05973969027400017    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            mAP            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7804883122444153     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           acc           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.939393937587738    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          loss           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05973969027400017   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           mAP           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7804883122444153    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results = minimal_trainer.test(\n",
    "    model, \n",
    "    dataloaders=test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db97a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
