{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1910ca",
   "metadata": {},
   "source": [
    "### Example usage for calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.utils.audio_to_spectrograms import create_spectrogram_pkl\n",
    "#from src.main import calculate_metrics\n",
    "\n",
    "# Copied from src.main as I'm having problems with audio mamba imports\n",
    "from src.config import CLASSES\n",
    "from loguru import logger\n",
    "import sed_eval\n",
    "\n",
    "def calculate_metrics(pred_event_dict, gt_event_dict, time_resolution=1.0, t_collar=0.25):\n",
    "    logger.warning(\"Metrics not implemented!\")\n",
    "    # Based on event dictionary\n",
    "\n",
    "    # Accuracy\n",
    "\n",
    "    # IoU\n",
    "\n",
    "    # DCASE SED eval: https://tut-arg.github.io/sed_eval/tutorial.html#id1\n",
    "    event_based_metrics = sed_eval.sound_event.EventBasedMetrics(CLASSES, t_collar=t_collar)\n",
    "    segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(CLASSES, time_resolution=time_resolution)\n",
    "    for file, estimated_event in pred_event_dict.items():\n",
    "        ref_event = gt_event_dict[file]\n",
    "        event_based_metrics.evaluate(\n",
    "            reference_event_list=ref_event,\n",
    "            estimated_event_list=estimated_event\n",
    "        )\n",
    "        segment_based_metrics.evaluate(\n",
    "            reference_event_list=ref_event,\n",
    "            estimated_event_list=estimated_event\n",
    "        )\n",
    "    print(event_based_metrics)\n",
    "    print(segment_based_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc6eb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to single_stage_yamnet_frame.ipynb (Section \"Get test set event predictions\") for pickle file generation\n",
    "pred_event_dict = pickle.load(open('outputs/single_stage_yamnet.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db5af036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'test_snipped_scene_0000.wav',\n",
       "  'event_onset': 0.96,\n",
       "  'event_offset': 3.84,\n",
       "  'event_label': 'siren'},\n",
       " {'file': 'test_snipped_scene_0000.wav',\n",
       "  'event_onset': 3.84,\n",
       "  'event_offset': 5.76,\n",
       "  'event_label': 'car_horn'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_event_dict['test_snipped_scene_0000.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02940f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('outputs/single_stage_yamnet.json', \"w\") as f:\n",
    "    json.dump(pred_event_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e262b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if pkl file is created\n",
    "gt_pkl_path = 'data/processed/yamnet/spectrograms_test_list.pkl'\n",
    "if not(os.path.exists(gt_pkl_path)):\n",
    "    create_spectrogram_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356bc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_events = pickle.load(open(gt_pkl_path, 'rb'))\n",
    "gt_event_dict = {ref_event['file']: [{'file':ref_event['file'], \n",
    "                    'event_onset':ref_event['onset'], \n",
    "                    'event_offset':ref_event['offset'],\n",
    "                    'event_label':ref_event['event_label']}]\n",
    "                    for ref_event in gt_events}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d8dd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'test_snipped_scene_0000.wav',\n",
       "  'event_onset': np.float64(1.5601864044243652),\n",
       "  'event_offset': np.float64(5.414698876079694),\n",
       "  'event_label': 'siren'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_event_dict['test_snipped_scene_0000.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7386bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outputs/crnn_results.json', \"r\") as f:\n",
    "    crnn_dict = json.load(f)\n",
    "crnn_dict = {k.replace('test_scene','test_snipped_scene'):v for k, v in crnn_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4178ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-03 22:21:29.931\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcalculate_metrics\u001b[0m:\u001b[36m15\u001b[0m - \u001b[33m\u001b[1mMetrics not implemented!\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'test_snipped_scene_0500.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrnn_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_event_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_collar\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mcalculate_metrics\u001b[39m\u001b[34m(pred_event_dict, gt_event_dict, time_resolution, t_collar)\u001b[39m\n\u001b[32m     23\u001b[39m event_based_metrics = sed_eval.sound_event.EventBasedMetrics(CLASSES, t_collar=t_collar)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file, estimated_event \u001b[38;5;129;01min\u001b[39;00m pred_event_dict.items():\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     ref_event = \u001b[43mgt_event_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     26\u001b[39m     event_based_metrics.evaluate(\n\u001b[32m     27\u001b[39m         reference_event_list=ref_event,\n\u001b[32m     28\u001b[39m         estimated_event_list=estimated_event\n\u001b[32m     29\u001b[39m     )\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(event_based_metrics)\n",
      "\u001b[31mKeyError\u001b[39m: 'test_snipped_scene_0500.wav'"
     ]
    }
   ],
   "source": [
    "calculate_metrics(crnn_dict, gt_event_dict, t_collar=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23215a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in crnn_dict.keys() if i not in gt_event_dict]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
