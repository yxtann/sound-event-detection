{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ac2dc1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6516c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 18:48:05.344957: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-06 18:48:05.345362: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-06 18:48:05.399361: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-06 18:48:19.282278: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-06 18:48:19.289600: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-06 18:48:35.008525: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#%load_ext autoreload\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "#from src.utils.audio_to_spectrograms import *\n",
    "from src.models.yamnet_train import *\n",
    "\n",
    "if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "    path_prefix = ''\n",
    "else:\n",
    "    path_prefix = '..'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7334cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment to retrain\n",
    "# manual train test split (stratified)\n",
    "\"\"\"np.random.seed(0)\n",
    "data = pickle.load(open('data/processed/yamnet/spectrograms_train.pkl', 'rb'))\n",
    "train_size = 0.8\n",
    "train_idx = []\n",
    "for label in np.unique(data['event_label']):\n",
    "    choices = np.where(data['event_label'] == label)[0]\n",
    "    train_idx.append(np.sort(np.random.choice(choices, size = int(np.round(len(choices)*train_size)), replace = False)))\n",
    "train_idx = np.sort(np.concatenate(train_idx))\n",
    "len(train_idx)\n",
    "\n",
    "solver = Solver(epochs = 5, train_idx=train_idx, path_prefix = path_prefix, device = device)\n",
    "solver.train()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e34337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-06 18:48:42.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.yamnet_train\u001b[0m:\u001b[36mrun_yamnet\u001b[0m:\u001b[36m351\u001b[0m - \u001b[1mLoading from checkpoint checkpoints/yamnet_detector.pth...\u001b[0m\n",
      "\u001b[32m2025-12-06 18:48:46.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.yamnet_train\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mLoaded model weights from checkpoints/yamnet_detector.pth\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for 500 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 520.53it/s]\n",
      "Testing...: 100%|██████████| 500/500 [00:07<00:00, 71.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = Path(\"data\") / \"processed\" / \"yamnet\" / \"spectrograms_test.pkl\"\n",
    "test_data = pickle.load(open(test_path, \"rb\"))\n",
    "filepaths = [os.path.join(DETECTION_TEST_PATH, file) for file in test_data['files']]\n",
    "events = run_yamnet(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae53039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'test_snipped_scene_0101.wav',\n",
       "  'event_onset': 6.24,\n",
       "  'event_offset': 12.0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['test_snipped_scene_0101.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cee4f2",
   "metadata": {},
   "source": [
    "# Cut audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import shutil\n",
    "#from src.main import cut_events_from_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47abb69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_events_from_audio(extracted_audio_path, events_list, data_path=DETECTION_TEST_PATH):\n",
    "\n",
    "    if not os.path.exists(extracted_audio_path):\n",
    "        os.makedirs(extracted_audio_path)\n",
    "        logger.info(f\"Created directory: {extracted_audio_path}\")\n",
    "    else:\n",
    "        # Clean the filepath as every prediction is new\n",
    "        shutil.rmtree(extracted_audio_path)\n",
    "        os.makedirs(extracted_audio_path)\n",
    "        logger.info(f\"Cleaned directory: {extracted_audio_path}\")\n",
    "\n",
    "    for filename, events in tqdm(events_list.items()):\n",
    "        filename = Path(data_path, filename)\n",
    "        for event in events:\n",
    "            start_sec = event[\"event_onset\"]\n",
    "            end_sec = event[\"event_offset\"]\n",
    "\n",
    "            audio_array, sr = sf.read(filename)\n",
    "            base_name = Path(filename).stem\n",
    "\n",
    "            # Cut the wav file and save it to the extracted_audio_path\n",
    "            start_sample = int(start_sec * sr)\n",
    "            end_sample = int(end_sec * sr)\n",
    "\n",
    "            # Slice the numpy array\n",
    "            sliced_audio = audio_array[start_sample:end_sample]\n",
    "\n",
    "            # Construct new filename\n",
    "            new_filename = f\"{base_name}_{start_sec:.2f}_{end_sec:.2f}.wav\"\n",
    "            output_path = extracted_audio_path / new_filename\n",
    "\n",
    "            # Write the new file\n",
    "            sf.write(output_path, sliced_audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b3ba870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-06 19:03:18.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcut_events_from_audio\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mCleaned directory: data/processed/yamnet/extracted_audio\u001b[0m\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:59<00:00,  8.37it/s]\n"
     ]
    }
   ],
   "source": [
    "cut_events_from_audio((Path(\"data\") / \"processed\" / \"yamnet\" / \"extracted_audio\"), events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
