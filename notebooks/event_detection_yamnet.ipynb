{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ac2dc1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 22:48:50.444578: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-09 22:48:50.444942: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-09 22:48:50.487926: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-09 22:49:17.236738: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-09 22:49:17.263609: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-09 22:49:49.375511: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#%load_ext autoreload\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.models.yamnet_train import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7771950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import sed_eval\n",
    "\n",
    "gt_pkl_path = 'data/processed/yamnet/spectrograms_train_list.pkl'\n",
    "\n",
    "gt_events = pickle.load(open(gt_pkl_path, 'rb'))\n",
    "gt_event_dict = {ref_event['file']: [{'file':ref_event['file'], \n",
    "                    'event_onset':ref_event['onset'], \n",
    "                    'event_offset':ref_event['offset'],\n",
    "                    'event_label':1}]\n",
    "                    for ref_event in gt_events}\n",
    "\n",
    "detection_classes = [1]\n",
    "\n",
    "def calculate_metrics(pred_event_dict, gt_event_dict, time_resolution=1.0, t_collar=0.25):\n",
    "\n",
    "    segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(detection_classes, time_resolution=time_resolution)\n",
    "    for file, estimated_event in pred_event_dict.items():\n",
    "        ref_event = gt_event_dict[file]\n",
    "        segment_based_metrics.evaluate(\n",
    "            reference_event_list=ref_event,\n",
    "            estimated_event_list=estimated_event\n",
    "        )\n",
    "    #print(segment_based_metrics)\n",
    "\n",
    "    return segment_based_metrics.results_overall_metrics()['f_measure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7334cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsolver = Solver(epochs = 5, train_idx=train_idx, path_prefix = path_prefix, device = device, batch_size = 8)\\nsolver.train()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual train test split (stratified)\n",
    "np.random.seed(0)\n",
    "data = pickle.load(open('data/processed/yamnet/spectrograms_train.pkl', 'rb'))\n",
    "train_size = 0.8\n",
    "train_idx = []\n",
    "for label in np.unique(data['event_label']):\n",
    "    choices = np.where(data['event_label'] == label)[0]\n",
    "    train_idx.append(np.sort(np.random.choice(choices, size = int(np.round(len(choices)*train_size)), replace = False)))\n",
    "train_idx = np.sort(np.concatenate(train_idx))\n",
    "\n",
    "# uncomment to retrain\n",
    "\"\"\"\n",
    "solver = Solver(epochs = 5, train_idx=train_idx, path_prefix = path_prefix, device = device, batch_size = 8)\n",
    "solver.train()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340d6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = list(range(len(data[\"event_label\"])))\n",
    "all_files = [f\"{DETECTION_TRAIN_PATH}/train_snipped_scene_{str(i).zfill(4)}.wav\" for i in all_indices]\n",
    "val_idx = [i for i in range(len(data[\"event_label\"])) if i not in train_idx]\n",
    "val_files = [all_files[i] for i in val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f63b8",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e34337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-09 22:50:10.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_yamnet\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading from checkpoint checkpoints/yamnet_detector.pth...\u001b[0m\n",
      "\u001b[32m2025-12-09 22:50:17.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.yamnet_train\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m188\u001b[0m - \u001b[1mLoaded model weights from checkpoints/yamnet_detector.pth\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for 500 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 606.40it/s]\n",
      "Testing...: 100%|██████████| 500/500 [00:06<00:00, 79.73it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = Path(\"data\") / \"processed\" / \"yamnet\" / \"spectrograms_test.pkl\"\n",
    "test_data = pickle.load(open(test_path, \"rb\"))\n",
    "filepaths = [os.path.join(DETECTION_TEST_PATH, file) for file in test_data['files']]\n",
    "events = run_yamnet(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae53039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'test_snipped_scene_0000.wav',\n",
       "  'event_onset': 1.92,\n",
       "  'event_offset': 5.76,\n",
       "  'ground_truth': 'siren',\n",
       "  'match': None}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['test_snipped_scene_0000.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce7e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_pkl_path = 'data/processed/yamnet/spectrograms_test_list.pkl'\n",
    "\n",
    "gt_events = pickle.load(open(gt_pkl_path, 'rb'))\n",
    "gt_event_dict = {ref_event['file']: [{'file':ref_event['file'], \n",
    "                    'event_onset':ref_event['onset'], \n",
    "                    'event_offset':ref_event['offset'],\n",
    "                    'event_label':1}]\n",
    "                    for ref_event in gt_events}\n",
    "\n",
    "pred_event_dict = {}\n",
    "for key, value in events.items():\n",
    "    for value_i in range(len(value)):\n",
    "        value[value_i] = value[value_i] | {\n",
    "            \"event_label\": 1\n",
    "        }\n",
    "    pred_event_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b457f929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f_measure': 0.8960910440376051,\n",
       " 'precision': 0.9253960143076136,\n",
       " 'recall': 0.8685851318944844}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import sed_eval\n",
    "\n",
    "detection_classes = [1]\n",
    "\n",
    "def calculate_metrics(pred_event_dict, gt_event_dict, time_resolution=1.0):\n",
    "\n",
    "    segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(detection_classes, time_resolution=time_resolution)\n",
    "    for file, estimated_event in pred_event_dict.items():\n",
    "        ref_event = gt_event_dict[file]\n",
    "        segment_based_metrics.evaluate(\n",
    "            reference_event_list=ref_event,\n",
    "            estimated_event_list=estimated_event\n",
    "        )\n",
    "    #print(segment_based_metrics)\n",
    "\n",
    "    return segment_based_metrics.results_overall_metrics()['f_measure']\n",
    "\n",
    "segment_based_metrics = calculate_metrics(pred_event_dict, gt_event_dict)\n",
    "segment_based_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cee4f2",
   "metadata": {},
   "source": [
    "# Cut audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import cut_events_from_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ba870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-06 11:28:27.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcut_events_from_audio\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mCreated directory: data/processed/yamnet/extracted_audio\u001b[0m\n",
      "100%|██████████| 500/500 [00:04<00:00, 100.53it/s]\n"
     ]
    }
   ],
   "source": [
    "cut_events_from_audio((Path(\"data\") / \"processed\" / \"yamnet\" / \"extracted_audio\"), events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
