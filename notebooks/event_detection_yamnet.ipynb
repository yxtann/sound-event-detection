{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ac2dc1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sed_eval loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6516c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765020371.235983     109 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#%load_ext autoreload\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "#from src.utils.audio_to_spectrograms import *\n",
    "from src.models.yamnet_train import *\n",
    "\n",
    "if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "    path_prefix = ''\n",
    "else:\n",
    "    path_prefix = '..'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7334cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for 2500 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]I0000 00:00:1765020396.813941     148 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "100%|██████████| 2500/2500 [01:10<00:00, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 0.1394\n",
      "Epoch 1: valildation loss = 0.1175\n",
      "Epoch 2: train loss = 0.0896\n",
      "Epoch 2: valildation loss = 0.0929\n",
      "Epoch 3: train loss = 0.0742\n",
      "Epoch 3: valildation loss = 0.0859\n",
      "Epoch 4: train loss = 0.0621\n",
      "Epoch 4: valildation loss = 0.0947\n",
      "Epoch 5: train loss = 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-06 11:28:10.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.yamnet_train\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mSaved model to checkpoints/yamnet_detector.pth\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: valildation loss = 0.0983\n"
     ]
    }
   ],
   "source": [
    "# uncomment to retrain\n",
    "# manual train test split (stratified)\n",
    "np.random.seed(0)\n",
    "data = pickle.load(open('data/processed/yamnet/spectrograms_train.pkl', 'rb'))\n",
    "train_size = 0.8\n",
    "train_idx = []\n",
    "for label in np.unique(data['event_label']):\n",
    "    choices = np.where(data['event_label'] == label)[0]\n",
    "    train_idx.append(np.sort(np.random.choice(choices, size = int(np.round(len(choices)*train_size)), replace = False)))\n",
    "train_idx = np.sort(np.concatenate(train_idx))\n",
    "len(train_idx)\n",
    "\n",
    "solver = Solver(epochs = 5, train_idx=train_idx, path_prefix = path_prefix, device = device)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e34337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-06 11:28:11.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.yamnet_train\u001b[0m:\u001b[36mrun_yamnet\u001b[0m:\u001b[36m351\u001b[0m - \u001b[1mLoading from checkpoint checkpoints/yamnet_detector.pth...\u001b[0m\n",
      "\u001b[32m2025-12-06 11:28:12.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.yamnet_train\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mLoaded model weights from checkpoints/yamnet_detector.pth\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing features for 500 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:11<00:00, 43.88it/s]\n",
      "Testing...: 100%|██████████| 500/500 [00:02<00:00, 227.88it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = Path(\"data\") / \"processed\" / \"yamnet\" / \"spectrograms_test.pkl\"\n",
    "test_data = pickle.load(open(test_path, \"rb\"))\n",
    "filepaths = [os.path.join(DETECTION_TEST_PATH, file) for file in test_data['files']]\n",
    "events = run_yamnet(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae53039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'test_snipped_scene_0000.wav',\n",
       "  'event_onset': 1.92,\n",
       "  'event_offset': 5.76}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['test_snipped_scene_0000.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ce7e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if pkl file is created\n",
    "gt_pkl_path = 'data/processed/yamnet/spectrograms_test_list.pkl'\n",
    "\n",
    "gt_events = pickle.load(open(gt_pkl_path, 'rb'))\n",
    "gt_event_dict = {ref_event['file']: [{'file':ref_event['file'], \n",
    "                    'event_onset':ref_event['onset'], \n",
    "                    'event_offset':ref_event['offset'],\n",
    "                    'event_label':1}]\n",
    "                    for ref_event in gt_events}\n",
    "\n",
    "pred_event_dict = {}\n",
    "for key, value in events.items():\n",
    "    for value_i in range(len(value)):\n",
    "        value[value_i] = value[value_i] | {\n",
    "            \"event_label\": 1\n",
    "        }\n",
    "    pred_event_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b457f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment based metrics\n",
      "========================================\n",
      "  Evaluated length                  : 4228.63 sec\n",
      "  Evaluated files                   : 500 \n",
      "  Segment length                    : 1.00 sec\n",
      "\n",
      "  Overall metrics (micro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 89.89 %\n",
      "    Precision                       : 92.98 %\n",
      "    Recall                          : 87.00 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 0.20 \n",
      "    Substitution rate               : 0.00 \n",
      "    Deletion rate                   : 0.13 \n",
      "    Insertion rate                  : 0.07 \n",
      "  Accuracy\n",
      "    Sensitivity                     : 87.00 %\n",
      "    Specificity                     : 94.28 %\n",
      "    Balanced accuracy               : 90.64 %\n",
      "    Accuracy                        : 90.89 %\n",
      "\n",
      "  Class-wise average metrics (macro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 89.89 %\n",
      "    Precision                       : 92.98 %\n",
      "    Recall                          : 87.00 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 0.20 \n",
      "    Deletion rate                   : 0.13 \n",
      "    Insertion rate                  : 0.07 \n",
      "  Accuracy\n",
      "    Sensitivity                     : 87.00 %\n",
      "    Specificity                     : 94.28 %\n",
      "    Balanced accuracy               : 90.64 %\n",
      "    Accuracy                        : 90.89 %\n",
      "  \n",
      "\n",
      "  Class-wise metrics\n",
      "  ======================================\n",
      "    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n",
      "    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n",
      "    1            | 2085    1951  | 89.9%    93.0%    87.0%  | 0.20     0.13     0.07   | 87.0%    94.3%    90.6%    90.9%   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import sed_eval\n",
    "\n",
    "detection_classes = [1]\n",
    "\n",
    "def calculate_metrics(pred_event_dict, gt_event_dict, time_resolution=1.0, t_collar=0.25):\n",
    "\n",
    "    segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(detection_classes, time_resolution=time_resolution)\n",
    "    for file, estimated_event in pred_event_dict.items():\n",
    "        ref_event = gt_event_dict[file]\n",
    "        segment_based_metrics.evaluate(\n",
    "            reference_event_list=ref_event,\n",
    "            estimated_event_list=estimated_event\n",
    "        )\n",
    "    print(segment_based_metrics)\n",
    "\n",
    "    return segment_based_metrics\n",
    "\n",
    "segment_based_metrics = calculate_metrics(pred_event_dict, gt_event_dict, t_collar=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cee4f2",
   "metadata": {},
   "source": [
    "# Cut audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b3b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main import cut_events_from_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3ba870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-06 11:28:27.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcut_events_from_audio\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mCreated directory: data/processed/yamnet/extracted_audio\u001b[0m\n",
      "100%|██████████| 500/500 [00:04<00:00, 100.53it/s]\n"
     ]
    }
   ],
   "source": [
    "cut_events_from_audio((Path(\"data\") / \"processed\" / \"yamnet\" / \"extracted_audio\"), events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
